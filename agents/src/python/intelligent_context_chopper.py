#!/usr/bin/env python3
"""
Intelligent Context Chopping System - Reduces context window while maintaining relevance
Leverages shadowgit (930M lines/sec) for rapid code analysis and ML for smart selection
"""

import os
import sys
import hashlib
import json
import time
import re
from typing import Dict, List, Tuple, Optional, Set, Any
from dataclasses import dataclass, field
from collections import defaultdict
from pathlib import Path
import subprocess
import secrets
from functools import lru_cache
import logging

# Security logging

# Add project root to Python path for imports
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from path_utilities import (
        get_project_root, get_agents_dir, get_database_dir,
        get_python_src_dir, get_shadowgit_paths, get_database_config
    )
except ImportError:
    # Fallback if path_utilities not available
    def get_project_root():
        return Path(__file__).parent.parent.parent
    def get_agents_dir():
        return get_project_root() / 'agents'
    def get_database_dir():
        return get_project_root() / 'database'
    def get_python_src_dir():
        return get_agents_dir() / 'src' / 'python'
    def get_shadowgit_paths():
        home_dir = Path.home()
        return {'root': home_dir / 'shadowgit'}
    def get_database_config():
        return {
            'host': 'localhost', 'port': 5433,
            'database': 'claude_agents_auth',
            'user': 'claude_agent', 'password': 'claude_auth_pass'
        }
logging.basicConfig(level=logging.INFO)
security_logger = logging.getLogger('security')

@dataclass
class ContextChunk:
    """A chunk of context with metadata"""
    content: str
    file_path: str
    start_line: int
    end_line: int
    relevance_score: float
    token_count: int
    security_level: str  # "public", "internal", "sensitive", "classified"
    dependencies: Set[str] = field(default_factory=set)
    last_accessed: float = field(default_factory=time.time)

@dataclass
class ContextWindow:
    """Optimized context window for API calls"""
    chunks: List[ContextChunk]
    total_tokens: int
    max_tokens: int = 8000  # Conservative limit
    security_cleared: bool = True
    metadata: Dict = field(default_factory=dict)

class IntelligentContextChopper:
    """
    Intelligently chops large codebases into relevant context windows
    Uses shadowgit for 930M lines/sec analysis and ML for relevance scoring
    Enhanced with rejection reduction capabilities for Claude Code optimization
    Enhanced with multi-level caching for performance
    """
    
    def __init__(self, max_context_tokens: int = 8000, 
                 security_mode: bool = True,
                 use_shadowgit: bool = True,
                 multilevel_cache=None):
        self.max_context_tokens = max_context_tokens
        self.security_mode = security_mode
        self.use_shadowgit = use_shadowgit
        self.multilevel_cache = multilevel_cache  # Integration with multi-level cache
        
        # Context storage (could be PostgreSQL in production)
        self.context_store: Dict[str, ContextChunk] = {}
        self.relevance_cache: Dict[str, float] = {}
        self.security_classifications: Dict[str, str] = {}
        
        # Learning system integration
        self.learning_patterns: Dict[str, List[str]] = defaultdict(list)
        self.success_patterns: List[Dict] = []
        
        # Shadowgit integration for rapid analysis
        self.shadowgit_available = self._check_shadowgit()
        
        # Security patterns to exclude
        # Compile security patterns for performance
        self.security_patterns = [
            re.compile(r'(api[_-]?key|secret|password|token|credential)', re.IGNORECASE),
            re.compile(r'(private[_-]?key|ssh[_-]?key|gpg[_-]?key)', re.IGNORECASE),
            re.compile(r'(aws[_-]?access|aws[_-]?secret|azure[_-]?key)', re.IGNORECASE),
            re.compile(r'(database[_-]?url|connection[_-]?string|mongodb://)', re.IGNORECASE),
            re.compile(r'(\.env|config\.json|secrets\.|credentials\.)', re.IGNORECASE),
            re.compile(r'(bearer\s+[a-zA-Z0-9\-\._~\+/]+)', re.IGNORECASE),
            re.compile(r'(-----BEGIN[^-]+PRIVATE KEY-----)', re.IGNORECASE),
        ]
        
        # Context relevance patterns
        self.relevance_patterns = {
            "high": [
                r'class\s+(\w+)',
                r'def\s+(\w+)',
                r'function\s+(\w+)',
                r'interface\s+(\w+)',
                r'type\s+(\w+)',
                r'CREATE\s+TABLE',
                r'error|exception|raise|throw',
            ],
            "medium": [
                r'import\s+',
                r'from\s+\w+\s+import',
                r'require\(',
                r'include\s+',
                r'TODO|FIXME|BUG',
            ],
            "low": [
                r'print\(|console\.log',
                r'//\s+|#\s+|\*\s+',
                r'test_|spec_',
            ]
        }
    
    def _check_shadowgit(self) -> bool:
        """Check if shadowgit is available for rapid analysis"""
        try:
            # Check for shadowgit AVX2 binary
            result = subprocess.run(
                ["which", "shadowgit"],
                capture_output=True,
                timeout=1
            )
            return result.returncode == 0
        except:
            return False
    
    def analyze_with_shadowgit(self, file_path: str) -> Dict[str, Any]:
        """Use shadowgit for ultra-fast file analysis (930M lines/sec)"""
        if not self.shadowgit_available:
            return self._fallback_analysis(file_path)
        
        try:
            # Use shadowgit's AVX2 processing
            result = subprocess.run(
                ["shadowgit", "analyze", "--avx2", file_path],
                capture_output=True,
                text=True,
                timeout=0.1  # 100ms timeout for most files
            )
            
            if result.returncode == 0:
                # Parse shadowgit output
                analysis = json.loads(result.stdout)
                return {
                    "lines_processed": analysis.get("lines", 0),
                    "processing_speed": "930M lines/sec",
                    "important_sections": analysis.get("sections", []),
                    "dependencies": analysis.get("imports", []),
                    "complexity": analysis.get("complexity", "medium")
                }
        except:
            pass
        
        return self._fallback_analysis(file_path)
    
    def _fallback_analysis(self, file_path: str) -> Dict[str, Any]:
        """Fallback analysis when shadowgit unavailable"""
        try:
            with open(file_path, 'r') as f:
                content = f.read()
                lines = content.split('\n')
                
            # Basic analysis
            imports = []
            functions = []
            classes = []
            
            for i, line in enumerate(lines):
                if re.match(r'import\s+|from\s+\w+\s+import', line):
                    imports.append(i)
                elif re.match(r'def\s+(\w+)', line):
                    functions.append(i)
                elif re.match(r'class\s+(\w+)', line):
                    classes.append(i)
            
            return {
                "lines_processed": len(lines),
                "processing_speed": "fallback",
                "important_sections": classes + functions,
                "dependencies": imports,
                "complexity": "unknown"
            }
        except:
            return {"error": "Could not analyze file"}
    
    def calculate_relevance_score(self, chunk: str, query: str, 
                                 history: List[str] = None) -> float:
        """Calculate relevance score using patterns and ML"""
        score = 0.0
        
        # Query matching (highest weight)
        query_terms = query.lower().split()
        chunk_lower = chunk.lower()
        for term in query_terms:
            if term in chunk_lower:
                score += 10.0
                # Bonus for exact matches
                if f" {term} " in chunk_lower:
                    score += 5.0
        
        # Pattern-based relevance
        for level, patterns in self.relevance_patterns.items():
            weight = {"high": 5.0, "medium": 3.0, "low": 1.0}[level]
            for pattern in patterns:
                matches = len(re.findall(pattern, chunk, re.IGNORECASE))
                score += matches * weight
        
        # Historical relevance (learning from past interactions)
        if history and chunk in self.relevance_cache:
            score += self.relevance_cache[chunk] * 2.0
        
        # Recency bias (recently modified files more relevant)
        # This would integrate with git history in production
        
        # Normalize score
        return min(score / 100.0, 1.0)
    
    def security_filter(self, chunk: str) -> Tuple[bool, str]:
        """Filter sensitive information for security with enhanced validation"""
        if not self.security_mode:
            return True, "unchecked"
        
        # Input validation
        if not isinstance(chunk, str) or len(chunk) > 1000000:  # 1MB max chunk size
            security_logger.warning(f"Invalid chunk size: {len(chunk) if isinstance(chunk, str) else 'non-string'}")
            return False, "invalid"
        
        # Check for security patterns with compiled regex for performance
        for pattern in self.security_patterns:
            if re.search(pattern, chunk):
                # Log security event
                security_logger.info(f"Sensitive pattern detected and redacted: {pattern.pattern}")
                # Redact sensitive parts
                chunk = re.sub(pattern, "[REDACTED]", chunk)
                return True, "redacted"
        
        # Classify security level
        if "internal" in chunk.lower() or "private" in chunk.lower():
            return True, "internal"
        elif "public" in chunk.lower() or "open" in chunk.lower():
            return True, "public"
        
        return True, "cleared"
    
    def chunk_file(self, file_path: str, chunk_size: int = 50) -> List[ContextChunk]:
        """Chunk a file into context pieces"""
        chunks = []
        
        try:
            with open(file_path, 'r') as f:
                lines = f.readlines()
            
            # Use shadowgit analysis if available
            analysis = self.analyze_with_shadowgit(file_path)
            important_lines = analysis.get("important_sections", [])
            
            # Smart chunking around important sections
            for i in range(0, len(lines), chunk_size):
                chunk_lines = lines[i:i+chunk_size]
                chunk_content = ''.join(chunk_lines)
                
                # Security filter
                is_safe, security_level = self.security_filter(chunk_content)
                if not is_safe and self.security_mode:
                    continue
                
                # Calculate token count (rough estimate)
                token_count = len(chunk_content.split()) * 1.3
                
                # Boost relevance if contains important sections
                relevance_boost = 0.2 if any(
                    i <= line < i+chunk_size for line in important_lines
                ) else 0.0
                
                chunk = ContextChunk(
                    content=chunk_content,
                    file_path=file_path,
                    start_line=i,
                    end_line=min(i+chunk_size, len(lines)),
                    relevance_score=relevance_boost,
                    token_count=int(token_count),
                    security_level=security_level
                )
                
                chunks.append(chunk)
                
                # Store in context store
                chunk_id = self._generate_chunk_id(file_path, i)
                self.context_store[chunk_id] = chunk
        
        except Exception as e:
            print(f"Error chunking file {file_path}: {e}")
        
        return chunks
    
    async def select_optimal_context(self, query: str, 
                                    files: List[str],
                                    max_tokens: Optional[int] = None) -> ContextWindow:
        """Select optimal context window for query"""
        max_tokens = max_tokens or self.max_context_tokens
        
        all_chunks = []
        
        # Process all files
        for file_path in files:
            chunks = self.chunk_file(file_path)
            
            # Calculate relevance for each chunk
            for chunk in chunks:
                chunk.relevance_score += self.calculate_relevance_score(
                    chunk.content, query
                )
            
            all_chunks.extend(chunks)
        
        # Sort by relevance
        all_chunks.sort(key=lambda x: x.relevance_score, reverse=True)
        
        # Build optimal context window
        selected_chunks = []
        total_tokens = 0
        
        for chunk in all_chunks:
            if total_tokens + chunk.token_count <= max_tokens:
                selected_chunks.append(chunk)
                total_tokens += chunk.token_count
                
                # Track for learning
                self.relevance_cache[chunk.content[:100]] = chunk.relevance_score
            else:
                break
        
        # Create context window
        window = ContextWindow(
            chunks=selected_chunks,
            total_tokens=total_tokens,
            max_tokens=max_tokens,
            security_cleared=all(c.security_level != "classified" 
                                for c in selected_chunks),
            metadata={
                "query": query,
                "files_analyzed": len(files),
                "chunks_selected": len(selected_chunks),
                "timestamp": time.time()
            }
        )
        
        # Store successful pattern for learning
        self._record_success_pattern(query, selected_chunks)
        
        return window
    
    def _generate_chunk_id(self, file_path: str, line_start: int) -> str:
        """Generate unique chunk ID with secure hashing"""
        data = f"{file_path}:{line_start}:{time.time_ns()}"
        return hashlib.sha256(data.encode()).hexdigest()
    
    def _record_success_pattern(self, query: str, chunks: List[ContextChunk]):
        """Record successful context selection for learning"""
        pattern = {
            "query": query,
            "timestamp": time.time(),
            "chunk_files": list(set(c.file_path for c in chunks)),
            "avg_relevance": sum(c.relevance_score for c in chunks) / len(chunks) if chunks else 0,
            "total_tokens": sum(c.token_count for c in chunks)
        }
        self.success_patterns.append(pattern)
        
        # Keep only recent patterns
        if len(self.success_patterns) > 1000:
            self.success_patterns = self.success_patterns[-1000:]
    
    async def get_context_for_request(self, query: str, 
                                      project_root: str = ".",
                                      file_extensions: List[str] = None) -> str:
        """Main entry point: Get optimized context for a request with multi-level caching"""
        
        # Generate cache key for this context request
        cache_key_data = f"context:{query}:{project_root}:{str(file_extensions)}"
        cache_key = hashlib.md5(cache_key_data.encode()).hexdigest()
        
        # Try multi-level cache first
        if self.multilevel_cache:
            try:
                cached_context = await self.multilevel_cache.get(f"context_chopper:{cache_key}")
                if cached_context:
                    security_logger.info(f"Context cache hit for query: {query[:50]}...")
                    return cached_context
            except Exception as e:
                security_logger.warning(f"Context cache error: {e}")
        
        # Default extensions
        if not file_extensions:
            file_extensions = ['.py', '.js', '.ts', '.md', '.yaml', '.json']
        
        # Find relevant files
        relevant_files = []
        for ext in file_extensions:
            for path in Path(project_root).rglob(f'*{ext}'):
                if not any(skip in str(path) for skip in 
                          ['node_modules', '__pycache__', '.git', 'venv']):
                    relevant_files.append(str(path))
        
        # Limit to most recent/relevant files
        relevant_files = relevant_files[:20]  # Process top 20 files
        
        # Get optimal context window
        window = await self.select_optimal_context(query, relevant_files)
        
        # Format context for API
        context_parts = []
        
        # Add metadata header
        context_parts.append(f"# Context Window: {window.total_tokens}/{window.max_tokens} tokens")
        context_parts.append(f"# Files: {window.metadata['files_analyzed']}, Chunks: {window.metadata['chunks_selected']}")
        context_parts.append("")
        
        # Add chunks with file markers
        current_file = None
        for chunk in window.chunks:
            if chunk.file_path != current_file:
                context_parts.append(f"\n--- File: {chunk.file_path} ---")
                current_file = chunk.file_path
            
            context_parts.append(f"Lines {chunk.start_line}-{chunk.end_line}:")
            context_parts.append(chunk.content)
        
        result = "\n".join(context_parts)
        
        # Cache the result in multi-level cache
        if self.multilevel_cache and result:
            try:
                await self.multilevel_cache.put(
                    f"context_chopper:{cache_key}", 
                    result, 
                    ttl_seconds=1800,  # 30 minutes for context
                    cache_level="L2"   # Store in L2 for sharing
                )
                security_logger.info(f"Cached context for query: {query[:50]}...")
            except Exception as e:
                security_logger.warning(f"Failed to cache context: {e}")
        
        return result
    
    async def get_context_for_files(self, query: str,
                                     files: List[str],
                                     max_tokens: Optional[int] = None) -> str:
        """
        Get optimized context for a query from a specific list of files.
        """

        # Generate cache key for this context request
        files_hash = hashlib.md5(str(sorted(files)).encode()).hexdigest()
        cache_key_data = f"context_files:{query}:{files_hash}:{max_tokens}"
        cache_key = hashlib.md5(cache_key_data.encode()).hexdigest()

        # Try multi-level cache first
        if self.multilevel_cache:
            try:
                cached_context = await self.multilevel_cache.get(f"context_chopper:{cache_key}")
                if cached_context:
                    security_logger.info(f"Context (files) cache hit for query: {query[:50]}...")
                    return cached_context
            except Exception as e:
                security_logger.warning(f"Context cache error: {e}")

        # Get optimal context window from the provided files
        window = await self.select_optimal_context(query, files, max_tokens)

        # Format context for API
        context_parts = []

        # Add metadata header
        context_parts.append(f"# Context Window: {window.total_tokens}/{window.max_tokens} tokens")
        context_parts.append(f"# Files: {window.metadata['files_analyzed']}, Chunks: {window.metadata['chunks_selected']}")
        context_parts.append("")

        # Add chunks with file markers
        current_file = None
        for chunk in window.chunks:
            if chunk.file_path != current_file:
                context_parts.append(f"\n--- File: {chunk.file_path} ---")
                current_file = chunk.file_path

            context_parts.append(f"Lines {chunk.start_line}-{chunk.end_line}:")
            context_parts.append(chunk.content)

        result = "\n".join(context_parts)

        # Cache the result in multi-level cache
        if self.multilevel_cache and result:
            try:
                await self.multilevel_cache.put(
                    f"context_chopper:{cache_key}",
                    result,
                    ttl_seconds=1800,  # 30 minutes for context
                    cache_level="L2"   # Store in L2 for sharing
                )
                security_logger.info(f"Cached context (files) for query: {query[:50]}...")
            except Exception as e:
                security_logger.warning(f"Failed to cache context: {e}")

        return result

    def export_learning_data(self) -> Dict:
        """Export learning data for PostgreSQL storage"""
        return {
            "relevance_cache": dict(self.relevance_cache),
            "success_patterns": self.success_patterns,
            "total_chunks_processed": len(self.context_store),
            "shadowgit_available": self.shadowgit_available
        }

    async def get_optimized_context(self, query: str, files: List[str], max_tokens: Optional[int] = None, intent: str = "general", security_mode: bool = True) -> ContextWindow:
        """
        Selects and formats an optimized context window from a given list of files.
        """
        # The 'intent' parameter is the query for relevance scoring.
        return await self.select_optimal_context(query, files, max_tokens)

class ContextChopperHooks:
    """Hooks for integrating with Claude's execution flow"""
    
    def __init__(self, chopper: IntelligentContextChopper):
        self.chopper = chopper
        self.enabled = True
    
    def pre_request_hook(self, request: Dict) -> Dict:
        """Hook before sending request to API"""
        if not self.enabled:
            return request
        
        # Extract query
        query = request.get("prompt", "")
        
        # Get optimized context
        context = self.chopper.get_context_for_request(
            query,
            project_root=request.get("project_root", "."),
            file_extensions=request.get("extensions", None)
        )
        
        # Replace full context with optimized version
        request["context"] = context
        request["metadata"] = {
            "context_chopped": True,
            "original_size": request.get("original_context_size", 0),
            "optimized_size": len(context)
        }
        
        return request
    
    def post_response_hook(self, response: Dict, request: Dict):
        """Hook after receiving response"""
        # Update relevance based on response quality
        if response.get("success", False):
            # Boost relevance scores for chunks that led to success
            for chunk_id in request.get("chunk_ids", []):
                if chunk_id in self.chopper.context_store:
                    chunk = self.chopper.context_store[chunk_id]
                    self.chopper.relevance_cache[chunk.content[:100]] *= 1.1

# Example usage
if __name__ == "__main__":
    # Initialize system
    chopper = IntelligentContextChopper(
        max_context_tokens=8000,
        security_mode=True,
        use_shadowgit=True
    )
    
    # Example query
    query = "Fix the authentication bug in the login system"
    
    # Get optimized context
    context = chopper.get_context_for_request(
        query,
        project_root=str(get_project_root()),
        file_extensions=['.py', '.md']
    )
    
    print(f"Optimized Context ({len(context)} chars):")
    print(context[:500] + "...")
    
    # Export learning data
    learning_data = chopper.export_learning_data()
    print(f"\nLearning Stats: {json.dumps(learning_data, indent=2)}")