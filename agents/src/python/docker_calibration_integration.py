#!/usr/bin/env python3
"""
Docker Calibration Integration v1.0
DOCKER-INTERNAL Agent Coordination for Think Mode Auto-Calibration

Multi-Agent Coordination:
- DOCKER-INTERNAL: Docker container orchestration and PostgreSQL integration
- ARCHITECT: Integration with auto-calibration architecture design
- NPU: Real-time analytics processing with neural acceleration
- INFRASTRUCTURE: Production deployment and monitoring

Features:
- Seamless integration with existing PostgreSQL Docker container (port 5433)
- Automated schema deployment and migration management
- Performance monitoring and analytics container orchestration
- Real-time learning data collection with Docker Compose integration
- Production-ready deployment with health checks and auto-restart

Purpose: Production Docker integration for think mode auto-calibration system
Copyright (C) 2025 Claude-Backups Framework
License: MIT
"""

import asyncio
import docker
import json
import time
import logging
import subprocess
import os
import yaml
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from pathlib import Path
import psycopg2
from psycopg2.extras import Json, RealDictCursor
import threading

@dataclass
class DockerServiceConfig:
    """Docker service configuration for calibration system"""
    service_name: str
    container_name: str
    image: str
    ports: Dict[str, int]
    environment: Dict[str, str]
    volumes: List[str]
    depends_on: List[str] = field(default_factory=list)
    health_check: Optional[Dict[str, Any]] = None
    restart_policy: str = "unless-stopped"

@dataclass
class DeploymentStatus:
    """Deployment status tracking"""
    service_name: str
    status: str  # 'running', 'stopped', 'error', 'deploying'
    container_id: Optional[str]
    health_status: str
    last_restart: Optional[datetime]
    error_message: Optional[str] = None

class DockerCalibrationOrchestrator:
    """Docker orchestration for think mode auto-calibration system"""

    def __init__(self, project_root: str = None):
        self.logger = self._setup_logging()
        self.project_root = Path(project_root or os.getcwd())

        # Docker client
        try:
            self.docker_client = docker.from_env()
            self.logger.info("Docker client initialized successfully")
        except Exception as e:
            self.logger.error(f"Docker client initialization failed: {e}")
            raise

        # Service configurations
        self.services = self._initialize_service_configs()
        self.deployment_status = {}

        # Monitoring
        self.monitoring_thread = None
        self.shutdown_event = threading.Event()

    def _setup_logging(self) -> logging.Logger:
        """Setup comprehensive logging for Docker integration"""
        logger = logging.getLogger("DockerCalibrationOrchestrator")
        logger.setLevel(logging.INFO)

        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            '%(asctime)s | %(levelname)-8s | DOCKER-INTEGRATION | %(message)s'
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)

        return logger

    def _initialize_service_configs(self) -> Dict[str, DockerServiceConfig]:
        """Initialize Docker service configurations"""
        return {
            'postgres': DockerServiceConfig(
                service_name='claude-postgres',
                container_name='claude-postgres',
                image='postgres:16',
                ports={'5432': 5433},
                environment={
                    'POSTGRES_DB': 'claude_agents_auth',
                    'POSTGRES_USER': 'claude_agent',
                    'POSTGRES_PASSWORD': 'claude_agent_pass',
                    'POSTGRES_HOST_AUTH_METHOD': 'md5'
                },
                volumes=[
                    'claude_postgres_data:/var/lib/postgresql/data',
                    f'{self.project_root}/agents/src/python/think_mode_calibration_schema.sql:/docker-entrypoint-initdb.d/calibration_schema.sql:ro'
                ],
                health_check={
                    'test': ['CMD-SHELL', 'pg_isready -U claude_agent -d claude_agents_auth'],
                    'interval': '30s',
                    'timeout': '10s',
                    'retries': 3,
                    'start_period': '60s'
                }
            ),

            'calibration_service': DockerServiceConfig(
                service_name='claude-calibration',
                container_name='claude-calibration',
                image='python:3.11-slim',
                ports={},
                environment={
                    'POSTGRES_HOST': 'claude-postgres',
                    'POSTGRES_PORT': '5432',
                    'POSTGRES_DB': 'claude_agents_auth',
                    'POSTGRES_USER': 'claude_agent',
                    'POSTGRES_PASSWORD': 'claude_agent_pass',
                    'CALIBRATION_FREQUENCY': '3600',
                    'MIN_FEEDBACK_SAMPLES': '50',
                    'AUTO_DEPLOYMENT': 'true'
                },
                volumes=[
                    f'{self.project_root}/agents/src/python:/app:ro',
                    'claude_calibration_logs:/var/log/calibration'
                ],
                depends_on=['claude-postgres'],
                health_check={
                    'test': ['CMD', 'python', '-c', 'import requests; requests.get("http://localhost:8080/health")'],
                    'interval': '60s',
                    'timeout': '10s',
                    'retries': 3
                }
            ),

            'analytics_dashboard': DockerServiceConfig(
                service_name='claude-analytics',
                container_name='claude-analytics',
                image='grafana/grafana:latest',
                ports={'3000': 3001},
                environment={
                    'GF_SECURITY_ADMIN_PASSWORD': 'claude_analytics',
                    'GF_USERS_ALLOW_SIGN_UP': 'false'
                },
                volumes=[
                    'claude_grafana_data:/var/lib/grafana',
                    f'{self.project_root}/config/grafana:/etc/grafana/provisioning:ro'
                ],
                depends_on=['claude-postgres']
            )
        }

    async def deploy_calibration_system(self) -> bool:
        """Deploy complete auto-calibration system using Docker"""
        self.logger.info("Starting deployment of auto-calibration system")

        try:
            # Step 1: Ensure PostgreSQL container is running with calibration schema
            if not await self._ensure_postgres_running():
                raise Exception("Failed to ensure PostgreSQL container")

            # Step 2: Deploy calibration schema
            if not await self._deploy_calibration_schema():
                raise Exception("Failed to deploy calibration schema")

            # Step 3: Generate and deploy Docker Compose configuration
            if not await self._generate_docker_compose():
                raise Exception("Failed to generate Docker Compose configuration")

            # Step 4: Deploy calibration service
            if not await self._deploy_calibration_service():
                raise Exception("Failed to deploy calibration service")

            # Step 5: Start monitoring services
            self._start_monitoring()

            self.logger.info("Auto-calibration system deployment completed successfully")
            return True

        except Exception as e:
            self.logger.error(f"Deployment failed: {e}")
            return False

    async def _ensure_postgres_running(self) -> bool:
        """Ensure PostgreSQL container is running"""
        try:
            # Check if container exists and is running
            try:
                container = self.docker_client.containers.get('claude-postgres')
                if container.status != 'running':
                    self.logger.info("Starting existing PostgreSQL container")
                    container.start()

                    # Wait for PostgreSQL to be ready
                    await self._wait_for_postgres_ready(container)

                self.logger.info("PostgreSQL container is running")
                return True

            except docker.errors.NotFound:
                self.logger.info("PostgreSQL container not found, creating new one")
                return await self._create_postgres_container()

        except Exception as e:
            self.logger.error(f"Failed to ensure PostgreSQL running: {e}")
            return False

    async def _create_postgres_container(self) -> bool:
        """Create new PostgreSQL container with calibration support"""
        try:
            config = self.services['postgres']

            # Create volume if it doesn't exist
            try:
                self.docker_client.volumes.get('claude_postgres_data')
            except docker.errors.NotFound:
                self.docker_client.volumes.create('claude_postgres_data')

            # Run container
            container = self.docker_client.containers.run(
                image=config.image,
                name=config.container_name,
                environment=config.environment,
                ports=config.ports,
                volumes=[
                    'claude_postgres_data:/var/lib/postgresql/data'
                ],
                restart_policy={'Name': config.restart_policy},
                detach=True,
                health={
                    'test': config.health_check['test'],
                    'interval': 30_000_000_000,  # 30 seconds in nanoseconds
                    'timeout': 10_000_000_000,   # 10 seconds in nanoseconds
                    'retries': 3,
                    'start_period': 60_000_000_000  # 60 seconds in nanoseconds
                }
            )

            self.logger.info(f"Created PostgreSQL container: {container.id[:12]}")

            # Wait for PostgreSQL to be ready
            await self._wait_for_postgres_ready(container)

            return True

        except Exception as e:
            self.logger.error(f"Failed to create PostgreSQL container: {e}")
            return False

    async def _wait_for_postgres_ready(self, container, timeout: int = 120) -> bool:
        """Wait for PostgreSQL to be ready for connections"""
        start_time = time.time()

        while time.time() - start_time < timeout:
            try:
                # Test connection
                result = container.exec_run(
                    'pg_isready -U claude_agent -d claude_agents_auth',
                    user='postgres'
                )

                if result.exit_code == 0:
                    self.logger.info("PostgreSQL is ready for connections")
                    return True

            except Exception as e:
                self.logger.debug(f"PostgreSQL not ready yet: {e}")

            await asyncio.sleep(5)

        self.logger.error(f"PostgreSQL did not become ready within {timeout} seconds")
        return False

    async def _deploy_calibration_schema(self) -> bool:
        """Deploy calibration schema to PostgreSQL"""
        try:
            # Connect to PostgreSQL
            db_config = {
                'host': 'localhost',
                'port': 5433,
                'database': 'claude_agents_auth',
                'user': 'claude_agent',
                'password': 'claude_agent_pass'
            }

            # Wait for connection to be available
            for attempt in range(10):
                try:
                    conn = psycopg2.connect(**db_config)
                    break
                except psycopg2.OperationalError:
                    if attempt < 9:
                        await asyncio.sleep(5)
                        continue
                    raise

            cursor = conn.cursor()

            # Load and execute schema
            schema_path = self.project_root / "agents/src/python/think_mode_calibration_schema.sql"
            if schema_path.exists():
                with open(schema_path, 'r') as f:
                    schema_sql = f.read()

                # Execute schema in chunks to handle large SQL files
                statements = schema_sql.split(';')
                for statement in statements:
                    statement = statement.strip()
                    if statement:
                        cursor.execute(statement)

                conn.commit()
                self.logger.info("Calibration schema deployed successfully")

                # Install pgvector extension if not already installed
                try:
                    cursor.execute("CREATE EXTENSION IF NOT EXISTS vector;")
                    conn.commit()
                    self.logger.info("pgvector extension ensured")
                except Exception as e:
                    self.logger.warning(f"pgvector extension installation failed: {e}")

            else:
                self.logger.error(f"Schema file not found: {schema_path}")
                return False

            cursor.close()
            conn.close()
            return True

        except Exception as e:
            self.logger.error(f"Schema deployment failed: {e}")
            return False

    async def _generate_docker_compose(self) -> bool:
        """Generate Docker Compose configuration for the calibration system"""
        try:
            compose_config = {
                'version': '3.8',
                'services': {},
                'volumes': {
                    'claude_postgres_data': {},
                    'claude_calibration_logs': {},
                    'claude_grafana_data': {}
                },
                'networks': {
                    'claude_calibration': {
                        'driver': 'bridge'
                    }
                }
            }

            # Add service configurations
            for service_name, config in self.services.items():
                service_config = {
                    'image': config.image,
                    'container_name': config.container_name,
                    'environment': config.environment,
                    'restart': config.restart_policy,
                    'networks': ['claude_calibration']
                }

                if config.ports:
                    service_config['ports'] = [f"{host}:{container}" for container, host in config.ports.items()]

                if config.volumes:
                    service_config['volumes'] = config.volumes

                if config.depends_on:
                    service_config['depends_on'] = config.depends_on

                if config.health_check:
                    service_config['healthcheck'] = config.health_check

                # Special configuration for calibration service
                if service_name == 'calibration_service':
                    service_config['command'] = [
                        'bash', '-c',
                        'pip install asyncio asyncpg psycopg2-binary numpy scikit-learn && '
                        'python /app/think_mode_auto_calibration.py'
                    ]
                    service_config['working_dir'] = '/app'

                compose_config['services'][service_name] = service_config

            # Write Docker Compose file
            compose_path = self.project_root / "docker-compose.calibration.yml"
            with open(compose_path, 'w') as f:
                yaml.dump(compose_config, f, default_flow_style=False, indent=2)

            self.logger.info(f"Docker Compose configuration written to {compose_path}")
            return True

        except Exception as e:
            self.logger.error(f"Failed to generate Docker Compose configuration: {e}")
            return False

    async def _deploy_calibration_service(self) -> bool:
        """Deploy calibration service using Docker Compose"""
        try:
            compose_path = self.project_root / "docker-compose.calibration.yml"

            if not compose_path.exists():
                self.logger.error("Docker Compose file not found")
                return False

            # Deploy using Docker Compose
            result = subprocess.run(
                ['docker-compose', '-f', str(compose_path), 'up', '-d'],
                cwd=self.project_root,
                capture_output=True,
                text=True
            )

            if result.returncode == 0:
                self.logger.info("Calibration services deployed successfully")
                return True
            else:
                self.logger.error(f"Docker Compose deployment failed: {result.stderr}")
                return False

        except Exception as e:
            self.logger.error(f"Failed to deploy calibration service: {e}")
            return False

    def _start_monitoring(self):
        """Start monitoring services for deployed containers"""
        def monitoring_loop():
            while not self.shutdown_event.is_set():
                try:
                    self._update_deployment_status()
                    self._check_container_health()
                    self._collect_performance_metrics()
                except Exception as e:
                    self.logger.error(f"Monitoring error: {e}")

                self.shutdown_event.wait(60)  # Check every minute

        self.monitoring_thread = threading.Thread(target=monitoring_loop, daemon=True)
        self.monitoring_thread.start()
        self.logger.info("Container monitoring started")

    def _update_deployment_status(self):
        """Update deployment status for all services"""
        for service_name, config in self.services.items():
            try:
                container = self.docker_client.containers.get(config.container_name)

                status = DeploymentStatus(
                    service_name=service_name,
                    status=container.status,
                    container_id=container.id[:12],
                    health_status=container.attrs.get('State', {}).get('Health', {}).get('Status', 'unknown'),
                    last_restart=None  # Would parse from container attrs in production
                )

                self.deployment_status[service_name] = status

            except docker.errors.NotFound:
                self.deployment_status[service_name] = DeploymentStatus(
                    service_name=service_name,
                    status='not_found',
                    container_id=None,
                    health_status='unknown',
                    last_restart=None,
                    error_message='Container not found'
                )

    def _check_container_health(self):
        """Check health of calibration system containers"""
        unhealthy_containers = []

        for service_name, status in self.deployment_status.items():
            if status.status != 'running' or status.health_status == 'unhealthy':
                unhealthy_containers.append(service_name)

        if unhealthy_containers:
            self.logger.warning(f"Unhealthy containers detected: {', '.join(unhealthy_containers)}")
            # In production, this would trigger alerts and potentially auto-restart

    def _collect_performance_metrics(self):
        """Collect performance metrics from calibration system"""
        try:
            # Collect metrics from PostgreSQL
            postgres_metrics = self._get_postgres_metrics()

            # Collect metrics from calibration service
            calibration_metrics = self._get_calibration_metrics()

            # Store metrics (would integrate with monitoring system in production)
            self.logger.debug(f"Performance metrics collected - "
                            f"Postgres: {len(postgres_metrics)} metrics, "
                            f"Calibration: {len(calibration_metrics)} metrics")

        except Exception as e:
            self.logger.debug(f"Metrics collection failed: {e}")

    def _get_postgres_metrics(self) -> Dict[str, Any]:
        """Get PostgreSQL performance metrics"""
        try:
            db_config = {
                'host': 'localhost',
                'port': 5433,
                'database': 'claude_agents_auth',
                'user': 'claude_agent',
                'password': 'claude_agent_pass'
            }

            conn = psycopg2.connect(**db_config)
            cursor = conn.cursor(cursor_factory=RealDictCursor)

            # Get basic metrics
            cursor.execute("""
                SELECT
                    COUNT(*) as total_decisions,
                    COUNT(*) FILTER (WHERE actual_complexity IS NOT NULL) as feedback_count,
                    AVG(processing_time_ms) as avg_processing_time
                FROM think_calibration.decision_tracking
                WHERE created_at >= NOW() - INTERVAL '1 hour'
            """)

            metrics = dict(cursor.fetchone() or {})

            cursor.close()
            conn.close()

            return metrics

        except Exception as e:
            self.logger.debug(f"Failed to collect PostgreSQL metrics: {e}")
            return {}

    def _get_calibration_metrics(self) -> Dict[str, Any]:
        """Get calibration service metrics"""
        # In production, this would query the calibration service API
        return {
            'calibration_service_status': 'running',
            'last_optimization': 'unknown',
            'current_accuracy': 'unknown'
        }

    async def get_system_status(self) -> Dict[str, Any]:
        """Get comprehensive system status"""
        return {
            'deployment_status': {name: status.__dict__ for name, status in self.deployment_status.items()},
            'docker_client_connected': self.docker_client is not None,
            'monitoring_active': self.monitoring_thread is not None and self.monitoring_thread.is_alive(),
            'postgres_metrics': self._get_postgres_metrics(),
            'calibration_metrics': self._get_calibration_metrics(),
            'system_health': self._calculate_system_health()
        }

    def _calculate_system_health(self) -> str:
        """Calculate overall system health"""
        running_services = sum(1 for status in self.deployment_status.values() if status.status == 'running')
        total_services = len(self.deployment_status)

        if running_services == total_services:
            return 'healthy'
        elif running_services > total_services * 0.5:
            return 'degraded'
        else:
            return 'critical'

    async def stop_calibration_system(self) -> bool:
        """Stop calibration system services"""
        try:
            compose_path = self.project_root / "docker-compose.calibration.yml"

            if compose_path.exists():
                result = subprocess.run(
                    ['docker-compose', '-f', str(compose_path), 'down'],
                    cwd=self.project_root,
                    capture_output=True,
                    text=True
                )

                if result.returncode == 0:
                    self.logger.info("Calibration system stopped successfully")
                else:
                    self.logger.warning(f"Docker Compose stop had issues: {result.stderr}")

            # Stop monitoring
            self.shutdown_event.set()
            if self.monitoring_thread:
                self.monitoring_thread.join(timeout=5)

            return True

        except Exception as e:
            self.logger.error(f"Failed to stop calibration system: {e}")
            return False

    def cleanup_resources(self):
        """Cleanup resources and temporary files"""
        try:
            # Stop monitoring
            self.shutdown_event.set()

            # Remove temporary Docker Compose files
            compose_path = self.project_root / "docker-compose.calibration.yml"
            if compose_path.exists():
                compose_path.unlink()

            self.logger.info("Resource cleanup completed")

        except Exception as e:
            self.logger.error(f"Resource cleanup failed: {e}")

async def main():
    """Main function for testing Docker integration"""
    print("="*80)
    print("Docker Calibration Integration v1.0")
    print("DOCKER-INTERNAL Agent Coordination")
    print("="*80)

    # Initialize Docker orchestrator
    orchestrator = DockerCalibrationOrchestrator()

    try:
        # Deploy calibration system
        print("\nüöÄ Deploying Auto-Calibration System:")
        if await orchestrator.deploy_calibration_system():
            print("‚úÖ Deployment successful")

            # Wait a moment for services to stabilize
            await asyncio.sleep(10)

            # Get system status
            status = await orchestrator.get_system_status()
            print(f"\nüìä System Status:")
            print(f"   System Health: {status['system_health']}")
            print(f"   Monitoring Active: {'Yes' if status['monitoring_active'] else 'No'}")
            print(f"   PostgreSQL Connected: {'Yes' if status['docker_client_connected'] else 'No'}")

            # Show deployment status
            print(f"\nüê≥ Service Status:")
            for service, deploy_status in status['deployment_status'].items():
                print(f"   {service}: {deploy_status['status']} "
                      f"(health: {deploy_status['health_status']})")

            print(f"\n‚úÖ Auto-calibration system deployed and operational")
            print(f"üîß Access analytics dashboard at: http://localhost:3001")
            print(f"üìä PostgreSQL calibration data at: localhost:5433")

        else:
            print("‚ùå Deployment failed")

    except KeyboardInterrupt:
        print(f"\n‚ö†Ô∏è  Stopping calibration system...")
        await orchestrator.stop_calibration_system()
        orchestrator.cleanup_resources()
        print("‚úÖ Shutdown complete")

    except Exception as e:
        print(f"‚ùå Error: {e}")
        orchestrator.cleanup_resources()

if __name__ == "__main__":
    asyncio.run(main())