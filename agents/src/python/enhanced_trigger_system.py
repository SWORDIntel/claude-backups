#!/usr/bin/env python3
"""
Enhanced Agent Trigger System with Trie-based Optimization

Integration module for high-performance agent keyword matching
Replaces linear search with O(1) trie lookups for production systems.

Usage:
    trigger_system = EnhancedTriggerSystem()
    result = trigger_system.analyze_request("optimize database performance")
    agents_to_invoke = result.get_priority_agents()
"""

import os
import logging
from typing import Dict, List, Set, Optional, Any
from dataclasses import dataclass
from trie_keyword_matcher import TrieKeywordMatcher, MatchResult

logger = logging.getLogger(__name__)

@dataclass
class AgentInvocationPlan:
    """Complete plan for agent invocation based on keyword analysis"""
    primary_agents: List[str]
    secondary_agents: List[str]
    execution_mode: str  # 'parallel', 'sequential', 'intelligent'
    confidence: float
    reasoning: str
    context_agents: Set[str]
    excluded_agents: Set[str]
    estimated_complexity: str  # 'simple', 'moderate', 'complex'

class EnhancedTriggerSystem:
    """
    Production-ready agent trigger system with trie-based optimization
    
    Features:
    - 10-20x faster keyword matching than linear search
    - Intelligent agent selection and prioritization  
    - Context-aware triggering based on file types and content
    - Negative trigger filtering to avoid unnecessary invocations
    - Compound pattern detection for complex workflows
    """
    
    def __init__(self, config_path: str = None):
        if not config_path:
            config_path = "/home/john/claude-backups/config/enhanced_trigger_keywords.yaml"
        
        self.trie_matcher = TrieKeywordMatcher(config_path)
        self.invocation_history: List[Dict] = []
        
        # Agent capability mapping for intelligent selection
        self.agent_capabilities = {
            # Strategic agents
            'DIRECTOR': ['strategy', 'planning', 'coordination', 'decision-making'],
            'PROJECTORCHESTRATOR': ['execution', 'coordination', 'workflow', 'task-management'],
            
            # Development agents
            'ARCHITECT': ['design', 'architecture', 'patterns', 'system-design'],
            'CONSTRUCTOR': ['implementation', 'scaffolding', 'project-setup'],
            'PATCHER': ['bug-fixes', 'code-surgery', 'problem-solving'],
            'DEBUGGER': ['analysis', 'troubleshooting', 'root-cause'],
            'LINTER': ['code-quality', 'standards', 'review'],
            'OPTIMIZER': ['performance', 'efficiency', 'bottlenecks'],
            
            # Testing agents
            'TESTBED': ['testing', 'validation', 'quality-assurance'],
            'QADIRECTOR': ['test-strategy', 'qa-leadership', 'quality-planning'],
            
            # Security agents
            'SECURITY': ['security-analysis', 'vulnerability-assessment'],
            'CSO': ['security-strategy', 'compliance', 'risk-management'],
            'BASTION': ['defensive-security', 'hardening', 'protection'],
            
            # Infrastructure agents
            'INFRASTRUCTURE': ['system-setup', 'configuration', 'deployment-prep'],
            'DEPLOYER': ['deployment', 'release-management', 'rollout'],
            'MONITOR': ['observability', 'metrics', 'alerting', 'monitoring'],
            
            # Specialized agents
            'DATABASE': ['data-architecture', 'schema-design', 'query-optimization'],
            'WEB': ['frontend', 'ui-development', 'web-frameworks'],
            'APIDESIGNER': ['api-design', 'contracts', 'integration'],
            'HARDWARE': ['low-level', 'hardware-optimization', 'system-programming'],
        }
    
    def analyze_request(self, text: str, context: Dict = None) -> AgentInvocationPlan:
        """
        Analyze request and create comprehensive agent invocation plan
        
        Args:
            text: Request text to analyze
            context: Optional context (file_extension, project_type, etc.)
        
        Returns:
            AgentInvocationPlan with prioritized agents and execution strategy
        """
        # Get trie-based keyword matching results
        match_result = self.trie_matcher.match(text, context)
        
        # Determine execution complexity
        complexity = self._assess_complexity(text, match_result)
        
        # Prioritize agents based on capabilities and context
        primary_agents, secondary_agents = self._prioritize_agents(
            match_result.agents, text, context
        )
        
        # Determine execution mode
        execution_mode = self._determine_execution_mode(match_result, complexity)
        
        # Calculate confidence score
        confidence = self._calculate_confidence(match_result, complexity)
        
        # Generate reasoning
        reasoning = self._generate_reasoning(match_result, complexity, execution_mode)
        
        # Apply context-aware filtering
        context_agents = self._get_context_agents(context) if context else set()
        excluded_agents = self._get_excluded_agents(text, context)
        
        plan = AgentInvocationPlan(
            primary_agents=primary_agents,
            secondary_agents=secondary_agents,
            execution_mode=execution_mode,
            confidence=confidence,
            reasoning=reasoning,
            context_agents=context_agents,
            excluded_agents=excluded_agents,
            estimated_complexity=complexity
        )
        
        # Log invocation for learning
        self._log_invocation(text, context, plan, match_result)
        
        return plan
    
    def get_priority_agents(self, text: str, context: Dict = None) -> List[str]:
        """Quick method to get prioritized agents for immediate invocation"""
        plan = self.analyze_request(text, context)
        return plan.primary_agents + list(plan.context_agents)
    
    def _assess_complexity(self, text: str, match_result: MatchResult) -> str:
        """Assess the complexity of the request"""
        # Count indicators of complexity
        complexity_indicators = [
            len(match_result.matched_triggers) > 3,  # Multiple trigger types
            len(match_result.agents) > 5,            # Many agents needed
            match_result.parallel_execution,         # Requires coordination
            any(word in text.lower() for word in [
                'multi-step', 'workflow', 'pipeline', 'orchestrat',
                'full stack', 'end-to-end', 'comprehensive'
            ]),
            # Compound pattern complexity
            len(text.split()) > 8,                   # Long request
        ]
        
        complexity_score = sum(complexity_indicators)
        
        if complexity_score >= 3:
            return 'complex'
        elif complexity_score >= 1:
            return 'moderate'
        else:
            return 'simple'
    
    def _prioritize_agents(self, agents: Set[str], text: str, context: Dict) -> tuple:
        """Prioritize agents based on capabilities and request context"""
        if not agents:
            return [], []
        
        primary_agents = []
        secondary_agents = []
        
        # Always prioritize strategic agents for complex tasks
        strategic_agents = {'DIRECTOR', 'PROJECTORCHESTRATOR'}
        if len(agents) > 3 or any(word in text.lower() for word in ['multi-step', 'complex', 'workflow']):
            for agent in strategic_agents:
                if agent in agents:
                    primary_agents.append(agent)
                    agents.remove(agent)
        
        # Prioritize based on keyword strength and agent capabilities
        agent_scores = {}
        for agent in agents:
            score = 0
            capabilities = self.agent_capabilities.get(agent, [])
            
            # Score based on capability match
            for capability in capabilities:
                if capability.replace('-', ' ') in text.lower():
                    score += 2
                if any(cap_word in text.lower() for cap_word in capability.split('-')):
                    score += 1
            
            agent_scores[agent] = score
        
        # Sort by score and split into primary/secondary
        sorted_agents = sorted(agent_scores.items(), key=lambda x: x[1], reverse=True)
        
        for agent, score in sorted_agents:
            if score >= 2 or len(primary_agents) < 3:
                primary_agents.append(agent)
            else:
                secondary_agents.append(agent)
        
        return primary_agents, secondary_agents
    
    def _determine_execution_mode(self, match_result: MatchResult, complexity: str) -> str:
        """Determine optimal execution mode for agents"""
        if match_result.parallel_execution:
            return 'parallel'
        elif match_result.sequential_execution:
            return 'sequential'
        elif complexity == 'complex':
            return 'intelligent'  # Let orchestrator decide
        else:
            return 'parallel'     # Default for simple tasks
    
    def _calculate_confidence(self, match_result: MatchResult, complexity: str) -> float:
        """Calculate confidence score for the invocation plan"""
        base_confidence = 0.7
        
        # Boost confidence with more matched triggers
        if len(match_result.matched_triggers) > 0:
            base_confidence += 0.1 * min(len(match_result.matched_triggers), 3)
        
        # Adjust for complexity
        complexity_multipliers = {
            'simple': 1.1,
            'moderate': 1.0,
            'complex': 0.9
        }
        
        confidence = base_confidence * complexity_multipliers.get(complexity, 1.0)
        return min(confidence, 1.0)
    
    def _generate_reasoning(self, match_result: MatchResult, complexity: str, execution_mode: str) -> str:
        """Generate human-readable reasoning for the invocation plan"""
        reasoning_parts = []
        
        if match_result.matched_triggers:
            reasoning_parts.append(f"Matched triggers: {', '.join(match_result.matched_triggers)}")
        
        if len(match_result.agents) > 0:
            reasoning_parts.append(f"Requires {len(match_result.agents)} specialized agents")
        
        if complexity != 'simple':
            reasoning_parts.append(f"Assessed as {complexity} complexity")
        
        if execution_mode == 'parallel':
            reasoning_parts.append("Agents can execute in parallel")
        elif execution_mode == 'sequential':
            reasoning_parts.append("Sequential execution required")
        
        return ". ".join(reasoning_parts) + "."
    
    def _get_context_agents(self, context: Dict) -> Set[str]:
        """Get additional agents based on context"""
        context_agents = set()
        
        if not context:
            return context_agents
        
        # File extension based agents
        file_ext = context.get('file_extension', '').lower()
        ext_mappings = {
            '.py': {'PYTHON-INTERNAL'},
            '.js': {'TYPESCRIPT-INTERNAL-AGENT', 'WEB'},
            '.ts': {'TYPESCRIPT-INTERNAL-AGENT'},
            '.rs': {'RUST-INTERNAL-AGENT'},
            '.go': {'GO-INTERNAL-AGENT'},
            '.c': {'C-INTERNAL', 'HARDWARE'},
            '.cpp': {'C-INTERNAL'},
            '.sql': {'DATABASE', 'SQL-INTERNAL-AGENT'},
            '.yaml': {'INFRASTRUCTURE', 'DEPLOYER'},
            '.yml': {'INFRASTRUCTURE', 'DEPLOYER'},
        }
        
        for ext, agents in ext_mappings.items():
            if file_ext.endswith(ext):
                context_agents.update(agents)
        
        return context_agents
    
    def _get_excluded_agents(self, text: str, context: Dict) -> Set[str]:
        """Get agents that should be excluded based on negative triggers"""
        excluded = set()
        
        # Exclude hardware agents for pure software tasks
        software_keywords = ['frontend', 'javascript', 'react', 'vue', 'angular', 'web', 'ui']
        if any(keyword in text.lower() for keyword in software_keywords):
            excluded.update({'HARDWARE', 'NPU', 'GNA'})
        
        return excluded
    
    def _log_invocation(self, text: str, context: Dict, plan: AgentInvocationPlan, 
                       match_result: MatchResult) -> None:
        """Log invocation for performance analysis and learning"""
        log_entry = {
            'text': text,
            'context': context,
            'match_time_ms': match_result.match_time_ms,
            'agents_count': len(plan.primary_agents) + len(plan.secondary_agents),
            'complexity': plan.estimated_complexity,
            'confidence': plan.confidence,
            'execution_mode': plan.execution_mode
        }
        
        self.invocation_history.append(log_entry)
        
        # Keep only last 1000 entries
        if len(self.invocation_history) > 1000:
            self.invocation_history = self.invocation_history[-1000:]
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """Get performance statistics including trie matcher stats"""
        trie_stats = self.trie_matcher.get_performance_stats()
        
        if self.invocation_history:
            avg_agents = sum(log['agents_count'] for log in self.invocation_history) / len(self.invocation_history)
            avg_confidence = sum(log['confidence'] for log in self.invocation_history) / len(self.invocation_history)
            complexity_counts = {}
            for log in self.invocation_history:
                complexity = log['complexity']
                complexity_counts[complexity] = complexity_counts.get(complexity, 0) + 1
        else:
            avg_agents = 0
            avg_confidence = 0
            complexity_counts = {}
        
        return {
            **trie_stats,
            'total_invocations': len(self.invocation_history),
            'avg_agents_per_request': avg_agents,
            'avg_confidence': avg_confidence,
            'complexity_distribution': complexity_counts,
        }


def demo_enhanced_trigger_system():
    """Demonstrate the enhanced trigger system capabilities"""
    print("=== ENHANCED AGENT TRIGGER SYSTEM DEMO ===\n")
    
    trigger_system = EnhancedTriggerSystem()
    
    demo_requests = [
        ("fix authentication bug in api", None),
        ("optimize database performance", {"file_extension": ".sql"}),
        ("create react frontend with tests", {"file_extension": ".tsx", "project_type": "web"}),
        ("security audit production deployment", None),
        ("multi-step machine learning pipeline", None),
        ("simple hello world script", {"file_extension": ".py"}),
    ]
    
    for i, (request, context) in enumerate(demo_requests, 1):
        print(f"{i}. Request: '{request}'")
        if context:
            print(f"   Context: {context}")
        
        plan = trigger_system.analyze_request(request, context)
        
        print(f"   Primary Agents: {plan.primary_agents}")
        if plan.secondary_agents:
            print(f"   Secondary Agents: {plan.secondary_agents}")
        if plan.context_agents:
            print(f"   Context Agents: {list(plan.context_agents)}")
        print(f"   Execution: {plan.execution_mode}")
        print(f"   Complexity: {plan.estimated_complexity}")
        print(f"   Confidence: {plan.confidence:.2f}")
        print(f"   Reasoning: {plan.reasoning}")
        print()
    
    # Performance stats
    stats = trigger_system.get_performance_stats()
    print("=== SYSTEM PERFORMANCE ===")
    print(f"Total Invocations: {stats['total_invocations']}")
    print(f"Average Agents per Request: {stats['avg_agents_per_request']:.1f}")
    print(f"Average Confidence: {stats['avg_confidence']:.2f}")
    print(f"Trie Build Time: {stats['build_time_ms']:.2f}ms")
    print(f"Memory Usage: {stats['trie_size_estimate_mb']:.2f}MB")


if __name__ == "__main__":
    demo_enhanced_trigger_system()