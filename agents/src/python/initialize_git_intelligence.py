#!/usr/bin/env python3
"""
Git Intelligence System Initialization
Team Echo Implementation

Sets up complete Git Intelligence infrastructure:
- PostgreSQL schema with pgvector
- ML model initialization
- Neural components setup
- Performance monitoring
- AVX2 integration testing
"""

import asyncio
import asyncpg
import json
import logging
import numpy as np
import os
import sys
import subprocess
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class GitIntelligenceInitializer:
    """Complete Git Intelligence system initializer"""
    
    def __init__(self, database_url: str = None):
        self.db_url = database_url or "postgresql://claude_agent:claude_secure_password@localhost:5433/claude_agents_auth"
        self.db_pool = None
        self.schema_file = Path(__file__).parent / "git_intelligence_schema_no_extension.sql"
        
        # Component status tracking
        self.components = {
            'database': False,
            'schema': False,
            'pgvector': False,
            'neural_models': False,
            'avx2_integration': False,
            'ml_models': False,
            'apis': False
        }
        
    async def initialize_complete_system(self) -> Dict[str, Any]:
        """Initialize the complete Git Intelligence system"""
        try:
            logger.info("Starting Git Intelligence System initialization...")
            start_time = time.time()
            
            # Step 1: Database connection
            await self._initialize_database()
            
            # Step 2: Install pgvector extension
            await self._setup_pgvector()
            
            # Step 3: Create database schema
            await self._create_schema()
            
            # Step 4: Initialize ML models
            await self._initialize_ml_models()
            
            # Step 5: Setup neural components
            await self._setup_neural_components()
            
            # Step 6: Test AVX2 integration
            await self._test_avx2_integration()
            
            # Step 7: Initialize APIs
            await self._initialize_apis()
            
            # Step 8: Run system tests
            test_results = await self._run_system_tests()
            
            # Step 9: Setup monitoring
            await self._setup_monitoring()
            
            total_time = time.time() - start_time
            
            # Generate initialization report
            report = {
                'initialization_successful': all(self.components.values()),
                'components_status': self.components,
                'initialization_time_seconds': total_time,
                'test_results': test_results,
                'timestamp': datetime.now().isoformat(),
                'database_url': self.db_url.replace('claude_secure_password', '***'),
                'recommendations': self._generate_recommendations()
            }
            
            if report['initialization_successful']:
                logger.info(f"‚úÖ Git Intelligence System initialized successfully in {total_time:.2f}s")
            else:
                logger.warning(f"‚ö†Ô∏è  Partial initialization completed in {total_time:.2f}s - check component status")
            
            return report
            
        except Exception as e:
            logger.error(f"‚ùå System initialization failed: {e}")
            return {
                'initialization_successful': False,
                'error': str(e),
                'components_status': self.components,
                'timestamp': datetime.now().isoformat()
            }
        finally:
            if self.db_pool:
                await self.db_pool.close()
    
    async def _initialize_database(self):
        """Initialize database connection and basic setup"""
        try:
            logger.info("üîå Connecting to PostgreSQL database...")
            
            # Test connection
            self.db_pool = await asyncpg.create_pool(
                self.db_url,
                min_size=2,
                max_size=10,
                command_timeout=30
            )
            
            # Test the connection
            async with self.db_pool.acquire() as conn:
                version = await conn.fetchval("SELECT version()")
                logger.info(f"üìä Connected to: {version.split(',')[0]}")
                
                # Check if we have sufficient permissions
                can_create_schema = await conn.fetchval("""
                    SELECT has_schema_privilege(current_user, 'public', 'CREATE')
                """)
                
                if not can_create_schema:
                    logger.warning("‚ö†Ô∏è  Limited database permissions - some features may be restricted")
            
            self.components['database'] = True
            logger.info("‚úÖ Database connection established")
            
        except Exception as e:
            logger.error(f"‚ùå Database initialization failed: {e}")
            raise
    
    async def _setup_pgvector(self):
        """Setup pgvector extension for neural embeddings"""
        try:
            logger.info("üß† Testing pgvector extension...")
            
            async with self.db_pool.acquire() as conn:
                # Test if extension is available and working
                try:
                    # Test vector operations
                    distance = await conn.fetchval("SELECT '[1,2,3]'::vector(3) <-> '[1,2,4]'::vector(3)")
                    logger.info(f"‚úÖ pgvector extension verified (test distance: {distance})")
                    self.components['pgvector'] = True
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  pgvector not available: {e}")
                    logger.info("üîÑ Neural embeddings will use fallback implementation")
                    self.components['pgvector'] = False
                    
        except Exception as e:
            logger.error(f"‚ùå pgvector setup failed: {e}")
    
    async def _create_schema(self):
        """Create the complete database schema"""
        try:
            logger.info("üèóÔ∏è  Creating Git Intelligence schema...")
            
            if not self.schema_file.exists():
                logger.error(f"‚ùå Schema file not found: {self.schema_file}")
                return
            
            # Read and execute schema
            schema_sql = self.schema_file.read_text()
            
            async with self.db_pool.acquire() as conn:
                # Execute schema in transaction
                async with conn.transaction():
                    await conn.execute(schema_sql)
                
                # Verify schema creation
                tables = await conn.fetch("""
                    SELECT table_name 
                    FROM information_schema.tables 
                    WHERE table_schema = 'git_intelligence'
                """)
                
                table_count = len(tables)
                logger.info(f"‚úÖ Created {table_count} tables in git_intelligence schema")
                
                # Verify indexes
                indexes = await conn.fetch("""
                    SELECT indexname 
                    FROM pg_indexes 
                    WHERE schemaname = 'git_intelligence'
                """)
                
                index_count = len(indexes)
                logger.info(f"‚úÖ Created {index_count} indexes for performance")
                
                self.components['schema'] = True
                
        except Exception as e:
            logger.error(f"‚ùå Schema creation failed: {e}")
            raise
    
    async def _initialize_ml_models(self):
        """Initialize ML models and training data structures"""
        try:
            logger.info("ü§ñ Initializing ML models...")
            
            async with self.db_pool.acquire() as conn:
                # Initialize base ML models
                models = [
                    ('conflict_predictor', 'v1.0', 'conflict_prediction'),
                    ('merge_suggester', 'v1.0', 'merge_strategy'),
                    ('code_reviewer', 'v1.0', 'code_quality'),
                    ('pattern_recognizer', 'v1.0', 'pattern_matching')
                ]
                
                for model_name, version, model_type in models:
                    await conn.execute("""
                        INSERT INTO git_intelligence.ml_models 
                        (model_name, model_version, model_type, model_accuracy, 
                         training_samples, performance_metrics)
                        VALUES ($1, $2, $3, $4, $5, $6)
                        ON CONFLICT (model_name) DO UPDATE SET
                            model_version = EXCLUDED.model_version,
                            updated_at = NOW()
                    """, 
                        model_name, version, model_type, 0.0, 0,
                        json.dumps({
                            'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0,
                            'training_time': 0, 'inference_time_ms': 0
                        })
                    )
                
                # Initialize pattern templates
                await self._initialize_pattern_templates(conn)
                
                self.components['ml_models'] = True
                logger.info("‚úÖ ML models initialized")
                
        except Exception as e:
            logger.error(f"‚ùå ML model initialization failed: {e}")
    
    async def _initialize_pattern_templates(self, conn):
        """Initialize common pattern templates for learning"""
        try:
            # Security patterns
            security_patterns = [
                {
                    'pattern_type': 'security',
                    'pattern_hash': 'sec_eval_usage',
                    'issue_description': 'Use of eval() function detected',
                    'fix_suggestion': 'Replace eval() with ast.literal_eval() or safer alternatives',
                    'confidence_score': 0.95,
                    'language': 'python'
                },
                {
                    'pattern_type': 'security',
                    'pattern_hash': 'sec_sql_injection',
                    'issue_description': 'Potential SQL injection vulnerability',
                    'fix_suggestion': 'Use parameterized queries or ORM methods',
                    'confidence_score': 0.9,
                    'language': 'python'
                }
            ]
            
            # Performance patterns
            performance_patterns = [
                {
                    'pattern_type': 'performance',
                    'pattern_hash': 'perf_range_len',
                    'issue_description': 'Inefficient range(len()) usage',
                    'fix_suggestion': 'Use enumerate() or direct iteration',
                    'confidence_score': 0.8,
                    'language': 'python'
                }
            ]
            
            # Quality patterns
            quality_patterns = [
                {
                    'pattern_type': 'quality',
                    'pattern_hash': 'qual_bare_except',
                    'issue_description': 'Bare except clause catches all exceptions',
                    'fix_suggestion': 'Specify exact exception types',
                    'confidence_score': 0.85,
                    'language': 'python'
                }
            ]
            
            all_patterns = security_patterns + performance_patterns + quality_patterns
            
            for pattern in all_patterns:
                await conn.execute("""
                    INSERT INTO git_intelligence.review_patterns 
                    (pattern_type, pattern_hash, issue_description, fix_suggestion, 
                     confidence_score, language, file_extensions)
                    VALUES ($1, $2, $3, $4, $5, $6, $7)
                    ON CONFLICT (pattern_hash) DO UPDATE SET
                        confidence_score = EXCLUDED.confidence_score,
                        occurrence_count = review_patterns.occurrence_count + 1
                """, 
                    pattern['pattern_type'], pattern['pattern_hash'],
                    pattern['issue_description'], pattern['fix_suggestion'],
                    pattern['confidence_score'], pattern['language'],
                    ['.py', '.pyx'] if pattern['language'] == 'python' else ['.js']
                )
            
            logger.info(f"‚úÖ Initialized {len(all_patterns)} pattern templates")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Pattern template initialization failed: {e}")
    
    async def _setup_neural_components(self):
        """Setup neural acceleration components"""
        try:
            logger.info("üß† Setting up neural components...")
            
            # Check for OpenVINO
            openvino_available = Path("${OPENVINO_ROOT:-/opt/openvino/}").exists()
            if openvino_available:
                logger.info("‚úÖ OpenVINO runtime detected")
                
                # Test neural inference capability
                try:
                    # This would initialize actual OpenVINO models in production
                    neural_test = np.random.random((1, 256))  # Simulate neural embedding
                    logger.info("‚úÖ Neural inference capability verified")
                    self.components['neural_models'] = True
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  Neural inference test failed: {e}")
                    self.components['neural_models'] = False
            else:
                logger.info("‚ÑπÔ∏è  OpenVINO not available - using CPU fallback for neural components")
                self.components['neural_models'] = False
            
            # Initialize embedding cache if pgvector is available
            if self.components['pgvector']:
                async with self.db_pool.acquire() as conn:
                    # Create sample embeddings for testing
                    test_embeddings = [
                        ('test_file.py', 'abc123', np.random.random(256).tolist(), 'python'),
                        ('test_file.js', 'def456', np.random.random(256).tolist(), 'javascript')
                    ]
                    
                    for file_path, commit_hash, embedding, language in test_embeddings:
                        await conn.execute("""
                            INSERT INTO git_intelligence.code_embeddings 
                            (file_path, commit_hash, embedding, content_hash, language)
                            VALUES ($1, $2, $3, $4, $5)
                            ON CONFLICT DO NOTHING
                        """, file_path, commit_hash, embedding, 
                            f"hash_{file_path}", language)
                    
                    logger.info("‚úÖ Neural embedding cache initialized")
            
        except Exception as e:
            logger.error(f"‚ùå Neural components setup failed: {e}")
    
    async def _test_avx2_integration(self):
        """Test AVX2 Shadowgit integration"""
        try:
            logger.info("‚ö° Testing AVX2 Shadowgit integration...")
            
            # Check if Shadowgit is available
            shadowgit_path = Path("/home/john/shadowgit/shadowgit_avx2.py")
            if shadowgit_path.exists():
                sys.path.append(str(shadowgit_path.parent))
                try:
                    from shadowgit_avx2 import ShadowgitAVX2
                    shadowgit = ShadowgitAVX2()
                    logger.info("‚úÖ Shadowgit AVX2 integration verified")
                    self.components['avx2_integration'] = True
                except ImportError as e:
                    logger.warning(f"‚ö†Ô∏è  Shadowgit AVX2 import failed: {e}")
                    self.components['avx2_integration'] = False
            else:
                logger.info("‚ÑπÔ∏è  Shadowgit AVX2 not available - using fallback diff analysis")
                self.components['avx2_integration'] = False
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  AVX2 integration test failed: {e}")
            self.components['avx2_integration'] = False
    
    async def _initialize_apis(self):
        """Initialize API components"""
        try:
            logger.info("üîå Initializing API components...")
            
            # Test import of main components
            components_to_test = [
                ('git_intelligence_engine', 'GitIntelligenceAPI'),
                ('conflict_predictor', 'ConflictPredictorAPI'),
                ('smart_merge_suggester', 'SmartMergeSuggesterAPI'),
                ('neural_code_reviewer', 'NeuralCodeReviewerAPI')
            ]
            
            successful_imports = 0
            for module_name, class_name in components_to_test:
                try:
                    module = __import__(module_name)
                    api_class = getattr(module, class_name)
                    logger.info(f"‚úÖ {class_name} imported successfully")
                    successful_imports += 1
                except ImportError as e:
                    logger.warning(f"‚ö†Ô∏è  {class_name} import failed: {e}")
                except AttributeError as e:
                    logger.warning(f"‚ö†Ô∏è  {class_name} not found in {module_name}: {e}")
            
            self.components['apis'] = successful_imports >= 3  # At least 3 out of 4
            
            if self.components['apis']:
                logger.info(f"‚úÖ API components initialized ({successful_imports}/4 successful)")
            else:
                logger.warning(f"‚ö†Ô∏è  Limited API availability ({successful_imports}/4 successful)")
                
        except Exception as e:
            logger.error(f"‚ùå API initialization failed: {e}")
            self.components['apis'] = False
    
    async def _run_system_tests(self) -> Dict[str, Any]:
        """Run comprehensive system tests"""
        try:
            logger.info("üß™ Running system tests...")
            
            test_results = {
                'database_connectivity': False,
                'schema_integrity': False,
                'vector_operations': False,
                'ml_model_storage': False,
                'pattern_matching': False,
                'performance_benchmarks': {}
            }
            
            async with self.db_pool.acquire() as conn:
                # Test 1: Database connectivity
                try:
                    await conn.fetchval("SELECT 1")
                    test_results['database_connectivity'] = True
                except:
                    pass
                
                # Test 2: Schema integrity
                try:
                    tables = await conn.fetch("""
                        SELECT table_name FROM information_schema.tables 
                        WHERE table_schema = 'git_intelligence'
                    """)
                    expected_tables = [
                        'git_operations', 'conflict_patterns', 'conflict_predictions',
                        'ml_models', 'code_reviews', 'code_issues'
                    ]
                    found_tables = [row['table_name'] for row in tables]
                    test_results['schema_integrity'] = all(
                        table in found_tables for table in expected_tables
                    )
                except:
                    pass
                
                # Test 3: Vector operations (if available)
                if self.components['pgvector']:
                    try:
                        distance = await conn.fetchval("""
                            SELECT '[1,2,3]'::vector(3) <-> '[1,2,4]'::vector(3)
                        """)
                        test_results['vector_operations'] = distance is not None
                    except:
                        pass
                
                # Test 4: ML model storage
                try:
                    model_count = await conn.fetchval("""
                        SELECT COUNT(*) FROM git_intelligence.ml_models
                    """)
                    test_results['ml_model_storage'] = model_count > 0
                except:
                    pass
                
                # Test 5: Pattern matching
                try:
                    pattern_count = await conn.fetchval("""
                        SELECT COUNT(*) FROM git_intelligence.review_patterns
                    """)
                    test_results['pattern_matching'] = pattern_count > 0
                except:
                    pass
            
            # Performance benchmarks
            start_time = time.time()
            
            # Database query performance
            async with self.db_pool.acquire() as conn:
                query_start = time.time()
                await conn.fetch("SELECT * FROM git_intelligence.ml_models LIMIT 10")
                query_time = (time.time() - query_start) * 1000
                
                test_results['performance_benchmarks']['db_query_ms'] = query_time
            
            # Vector similarity (if available)
            if self.components['pgvector']:
                async with self.db_pool.acquire() as conn:
                    vector_start = time.time()
                    await conn.fetchval("""
                        SELECT '[1,2,3,4,5]'::vector(5) <-> '[1,2,3,4,6]'::vector(5)
                    """)
                    vector_time = (time.time() - vector_start) * 1000
                    
                    test_results['performance_benchmarks']['vector_similarity_ms'] = vector_time
            
            total_test_time = time.time() - start_time
            test_results['performance_benchmarks']['total_test_time_ms'] = total_test_time * 1000
            
            passed_tests = sum(1 for result in test_results.values() 
                             if isinstance(result, bool) and result)
            total_tests = sum(1 for result in test_results.values() 
                            if isinstance(result, bool))
            
            logger.info(f"‚úÖ System tests completed: {passed_tests}/{total_tests} passed")
            
            return test_results
            
        except Exception as e:
            logger.error(f"‚ùå System tests failed: {e}")
            return {'error': str(e)}
    
    async def _setup_monitoring(self):
        """Setup system monitoring and metrics collection"""
        try:
            logger.info("üìä Setting up monitoring...")
            
            async with self.db_pool.acquire() as conn:
                # Initialize system metrics
                initial_metrics = [
                    ('system', 'initialization_time', time.time(), 'seconds', 'system'),
                    ('database', 'connection_pool_size', 10, 'connections', 'database'),
                    ('neural', 'models_loaded', 1 if self.components['neural_models'] else 0, 'count', 'neural'),
                    ('avx2', 'acceleration_available', 1 if self.components['avx2_integration'] else 0, 'boolean', 'performance')
                ]
                
                for metric_type, metric_name, value, unit, component in initial_metrics:
                    await conn.execute("""
                        INSERT INTO git_intelligence.system_metrics 
                        (metric_type, metric_name, metric_value, metric_unit, component)
                        VALUES ($1, $2, $3, $4, $5)
                    """, metric_type, metric_name, value, unit, component)
                
                logger.info("‚úÖ Monitoring setup completed")
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Monitoring setup failed: {e}")
    
    def _generate_recommendations(self) -> List[str]:
        """Generate recommendations based on initialization results"""
        recommendations = []
        
        if not self.components['pgvector']:
            recommendations.append(
                "Consider installing pgvector extension for enhanced neural embedding performance"
            )
        
        if not self.components['neural_models']:
            recommendations.append(
                "Install OpenVINO runtime at ${OPENVINO_ROOT:-/opt/openvino/} for neural acceleration"
            )
        
        if not self.components['avx2_integration']:
            recommendations.append(
                "Deploy Shadowgit AVX2 for high-performance diff analysis"
            )
        
        if self.components['database'] and self.components['schema']:
            recommendations.append(
                "System is ready for production use - consider running performance tuning"
            )
        
        if not all(self.components.values()):
            recommendations.append(
                "Some components failed to initialize - check logs for detailed error information"
            )
        
        return recommendations


async def main():
    """Main initialization function"""
    try:
        print("üöÄ Git Intelligence System Initialization Starting...")
        print("=" * 60)
        
        # Initialize system
        initializer = GitIntelligenceInitializer()
        report = await initializer.initialize_complete_system()
        
        # Display results
        print("\n" + "=" * 60)
        print("üìã INITIALIZATION REPORT")
        print("=" * 60)
        
        if report['initialization_successful']:
            print("‚úÖ Status: SUCCESSFUL")
        else:
            print("‚ùå Status: FAILED")
            if 'error' in report:
                print(f"üí• Error: {report['error']}")
        
        print(f"‚è±Ô∏è  Time: {report.get('initialization_time_seconds', 0):.2f} seconds")
        print(f"üìÖ Timestamp: {report['timestamp']}")
        
        print("\nüîß Component Status:")
        for component, status in report['components_status'].items():
            status_icon = "‚úÖ" if status else "‚ùå"
            print(f"  {status_icon} {component.replace('_', ' ').title()}")
        
        if 'test_results' in report:
            print("\nüß™ Test Results:")
            for test, result in report['test_results'].items():
                if isinstance(result, bool):
                    status_icon = "‚úÖ" if result else "‚ùå"
                    print(f"  {status_icon} {test.replace('_', ' ').title()}")
                elif isinstance(result, dict) and test == 'performance_benchmarks':
                    print(f"  üìä Performance Benchmarks:")
                    for metric, value in result.items():
                        print(f"    ‚Ä¢ {metric}: {value:.2f}")
        
        if 'recommendations' in report and report['recommendations']:
            print("\nüí° Recommendations:")
            for rec in report['recommendations']:
                print(f"  ‚Ä¢ {rec}")
        
        print("\n" + "=" * 60)
        
        if report['initialization_successful']:
            print("üéâ Git Intelligence System is ready for production use!")
            
            print("\nüìö Available APIs:")
            print("  ‚Ä¢ GitIntelligenceAPI - Main git analysis engine")
            print("  ‚Ä¢ ConflictPredictorAPI - ML conflict prediction")
            print("  ‚Ä¢ SmartMergeSuggesterAPI - Intelligent merge strategies")
            print("  ‚Ä¢ NeuralCodeReviewerAPI - AI-powered code review")
            
            print("\nüöÄ Quick Start:")
            print("  from git_intelligence_engine import GitIntelligenceAPI")
            print("  api = GitIntelligenceAPI('/path/to/repo')")
            print("  await api.initialize()")
            print("  conflicts = await api.predict_conflicts()")
        else:
            print("‚ö†Ô∏è  System partially initialized - check component status above")
        
        print("=" * 60)
        
        # Save report to file
        report_file = Path(__file__).parent / f"initialization_report_{int(time.time())}.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2, default=str)
        
        print(f"üìÑ Full report saved to: {report_file}")
        
    except Exception as e:
        print(f"üí• Initialization failed with critical error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())